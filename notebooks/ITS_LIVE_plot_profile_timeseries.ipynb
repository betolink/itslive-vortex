{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6636d5cd-6da2-4e63-92d8-afc7deb9c87d",
   "metadata": {},
   "source": [
    "**ITS_LIVE Python Library Demo: Time Series of Ice Flow Speed Along a Profile (like a centerline)**\n",
    "\n",
    "ITS_LIVE (Intermission Time Series of Land Ice Velocity and Elevation, http:itslive.jpl.nasa.gov) maintains an archive of ice flow speeds for glaciers and ice sheets.\n",
    "These speeds are determined from pairs of satellite images by tracking how far features move from the first image in a pair to the second image in a pair.\n",
    "\n",
    "As a result, the time series of ice motion at a single location on a glacier consist of measurements of the average speed of the ice at that point over the time interval between the two images used.\n",
    "\n",
    "Because ITS_LIVE determines the offsets between the two images on a regular 120 m grid, resulting in a velocity map from each image pair, and because these velocity maps are then stacked in time in \"Data Cubes\", it is possble to efficiently extract time series for a vector of points, such as evenly spaced points along a center flow line.\n",
    "\n",
    "In this notebook we extract such a dataset, and then plot it in a way to visualize the time evolution of ice flow along that centerline.\n",
    "\n",
    "The profile used below is defined by 4 points:\n",
    "![alt text](Screenshot_Malaspina_profile_points.png \"Malaspina Centerline Profile Points\")\n",
    "\n",
    "You can generate the above figure, including locations of these points and the speed histories at the points, here: https://mappin.itsliveiceflow.science/chart?lat=59.75571&lng=-140.83322&c=b&lat=59.86874&lng=-140.75332&c=g&lat=59.97592&lng=-140.62665&c=r&lat=60.08311&lng=-140.46295&c=y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d4ec6-8046-41ff-b0c3-3a75bea46142",
   "metadata": {},
   "source": [
    "**the code below generates an evenly sampled set of points along that profile and plots the detailed ice flow history along that profile from ITS_LIVE data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98368f4f-42cc-4dcb-94ce-388f482de2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'itslive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitslive\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transformer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutm\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'itslive'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import itslive\n",
    "from pyproj import Transformer\n",
    "import utm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# we need several matplotlib components to make this plot\n",
    "from matplotlib import pyplot as plt\n",
    "# from matplotlib import collections  as mc\n",
    "# from matplotlib import dates as mdates\n",
    "from matplotlib import colors as mpl_colors\n",
    "from matplotlib import cm  as mpl_cm\n",
    "from matplotlib import ticker as mpl_ticker\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def dt64_to_decimal_year(dt64_in):\n",
    "    year_int = dt64_in.astype('datetime64[Y]').astype(int) + 1970\n",
    "    days_in_year = ( np.datetime64(f\"{year_int+1}-01-01\") - np.datetime64(f\"{year_int}-01-01\") ).astype(float)\n",
    "    decimal_year = float(year_int) + ( ( dt64_in - np.datetime64(f\"{year_int}-01-01T00:00\") ).astype('timedelta64[D]').astype(float) / days_in_year )\n",
    "    return decimal_year\n",
    "\n",
    "def vec_dt64_to_decimal_year(vec_dt64_in):\n",
    "    out_dec_year_list = []\n",
    "    for dt64_in in vec_dt64_in:\n",
    "        out_dec_year_list.append(dt64_to_decimal_year(dt64_in))\n",
    "    return np.array(out_dec_year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9d23f-359a-4ee1-8a3c-0b5b5f7bffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "itslive.velocity_cubes._catalog = itslive.velocity_cubes.load_catalog(\"https://its-live-data.s3.amazonaws.com/datacubes/catalog_final_v2_temp.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ff892-1930-401d-be64-28fe10a9266a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# specify centerline lon,lat pairs\n",
    "#\n",
    "# find appropriate projection, convert points to that projection, generate evenly spaced sample points, convert back to lon,lat for itslive call\n",
    "#\n",
    "\n",
    "del_interval = 1000.0 # sample every del_interval meters along profile\n",
    "\n",
    "# profile:\n",
    "centerline_lon_lat_list = [\n",
    "                            (-140.83322058712292, 59.7557082654018),\n",
    "                            (-140.7533199251939, 59.86873847008192),\n",
    "                            (-140.62664814408686, 59.975922284864794),\n",
    "                            (-140.46294922696393, 60.083106099647665),\n",
    "                          ]\n",
    "# find best projection for evenly spacing sample points (lat,lon won't work)\n",
    "mean_lon = np.mean([x for x,y in centerline_lon_lat_list])\n",
    "mean_lat = np.mean([y for x,y in centerline_lon_lat_list])\n",
    "\n",
    "x,y,zone_num,zone_letter = utm.from_latlon(mean_lat,mean_lon)\n",
    "if mean_lat < -65.0: # Antarctica - SCAR PS\n",
    "    epsg = 3031\n",
    "elif mean_lat > 65: # northern NSIDC PS\n",
    "    epsg = 3413\n",
    "else: # figure out local UTM\n",
    "    x,y,zone_num,zone_letter = utm.from_latlon(mean_lat,mean_lon)\n",
    "    if mean_lat >= 0.0:\n",
    "        epsg = int(f'326{zone_num:02d}')\n",
    "    else:\n",
    "        epsg = int(f'327{zone_num:02d}')\n",
    "\n",
    "print(f'using EPSG:{epsg}')\n",
    "\n",
    "# set up tranformations to local xy projection to evenly space; and from that xy back to lat,lon\n",
    "ll_to_xy_transformer = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{epsg}\")\n",
    "xy_to_ll_transformer = Transformer.from_crs(f\"EPSG:{epsg}\",\"EPSG:4326\")\n",
    "\n",
    "pts_xy = []\n",
    "for lon,lat in centerline_lon_lat_list:\n",
    "    x,y = ll_to_xy_transformer.transform(lat,lon)\n",
    "    print(f'{x} {y} {lon} {lat}')\n",
    "    pts_xy.append((x,y))\n",
    "\n",
    "\n",
    "deldiffs=np.diff(pts_xy,axis=0)   # delta x and delta y between adjacent points\n",
    "deldist=[np.sqrt(x**2 + y**2) for x,y in deldiffs]\n",
    "cl_dist=np.zeros(len(pts_xy))\n",
    "cl_dist[1:]=np.cumsum(deldist)  # set to be zero distance at start\n",
    "mfdel=np.modf(cl_dist/del_interval)\n",
    "ddint=np.diff(mfdel[1])    # integer part of ratio above - then find steps in that\n",
    "\n",
    "num_samp_pnts=np.max(mfdel[1]).astype(int) + 1    # maximum number of integer del_intervals that fit in cl_dist max\n",
    "samp_pnts_x=np.zeros(num_samp_pnts)\n",
    "samp_pnts_y=np.zeros(num_samp_pnts)\n",
    "samp_pnts_x[0]=pts_xy[0][0]\n",
    "samp_pnts_y[0]=pts_xy[0][1]\n",
    "samp_pnts_dist=np.arange(0.0,del_interval * num_samp_pnts,del_interval)\n",
    "samp_pnts_dist\n",
    "\n",
    "for i in np.where(ddint>0)[0]:\n",
    "    numpntstoadd=ddint[i]\n",
    "    pntindex=mfdel[1].astype(int)[i]    # mfdel[1] is integer part of mod - so the point index for regularly spaced points\n",
    "    delx=deldiffs[i][0]\n",
    "    dely=deldiffs[i][1]\n",
    "    startx=pts_xy[i][0]\n",
    "    starty=pts_xy[i][1]\n",
    "    for j in range(1,int(numpntstoadd)+1):\n",
    "        frac= (deldist[i] - (del_interval*(float(numpntstoadd - j) + mfdel[0][i+1])))/deldist[i]    # fraction of total input pnt distance for the jth integer point\n",
    "        samp_pnts_x[pntindex+j]=startx + (frac*delx)\n",
    "        samp_pnts_y[pntindex+j]=starty + (frac*dely)\n",
    "\n",
    "samp_pnts_lat, samp_pnts_lon = xy_to_ll_transformer.transform(samp_pnts_x,samp_pnts_y)\n",
    "\n",
    "dist_min, dist_max = samp_pnts_dist[0], samp_pnts_dist[-1]\n",
    "\n",
    "disthalfbin = (samp_pnts_dist[1] - samp_pnts_dist[0])/2.0 # for plotting patches\n",
    "\n",
    "num_sample_points = len(samp_pnts_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228477d5-a91b-4010-9f4a-16acf33519cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# get itslive data at each of the evenly spaced points\n",
    "\n",
    "print(f'fetching time series for {len(samp_pnts_dist)} points', flush=True)\n",
    "tseries = itslive.velocity_cubes.get_time_series(zip(samp_pnts_lon,samp_pnts_lat),variables=['v','acquisition_date_img1','acquisition_date_img2','date_dt'])\n",
    "print(f'done fetching time series', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae5508-3e5e-44bf-8539-fd24816cfb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up limits for plot\n",
    "plot_speed_max = 2800 # m/yr\n",
    "# plot_speed_max = 6000 # m/yr\n",
    "\n",
    "use_logscale = False\n",
    "\n",
    "# year_min = 1985.0\n",
    "year_min = 1985.0\n",
    "year_max = 2023.1\n",
    "\n",
    "speed_min = 0\n",
    "# year_min = profiles[0][1]['start_dec_year']\n",
    "# year_max = profiles[-1][1]['stop_dec_year']\n",
    "\n",
    "# colormap = plt.get_cmap('viridis') \n",
    "colormap = plt.get_cmap('jet') \n",
    "# cNorm  = colors.Normalize(vmin=0, vmax=plot_speed_max)\n",
    "if use_logscale == True:\n",
    "    cNorm  = mpl_colors.LogNorm(vmin=10.0, vmax=plot_speed_max)\n",
    "else:\n",
    "    cNorm  = mpl_colors.Normalize(vmin=0.0, vmax=plot_speed_max)\n",
    "\n",
    "scalarMap = mpl_cm.ScalarMappable(norm=cNorm, cmap=colormap)\n",
    "print(scalarMap.get_clim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905b930-15c7-468b-9930-8954085c10d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotted_points = []\n",
    "\n",
    "#\n",
    "# for each evenly spaced point on the profile, calculate polygons for every velocity measurement at that point that\n",
    "# extend from half way to the prior and next points in x, and from the date of the first image to the date of the second image used for speed in the y (time) axis\n",
    "# note that the points are sorted by reverse of the time separation between the images (date_dt in days), so that longer date_dts are plotted first, underneath shorter date_dts\n",
    "# this keeps the long intervals from covering the shorter ones - showing all the short time variation in the record\n",
    "#\n",
    "\n",
    "for i,dist in tqdm( enumerate(samp_pnts_dist), total = len(samp_pnts_dist), desc = 'calculating points'):\n",
    "    if i==0:\n",
    "        x_start = dist\n",
    "        x_stop = dist + disthalfbin\n",
    "    elif i==num_sample_points - 1:\n",
    "        x_start = dist - disthalfbin\n",
    "        x_stop = dist\n",
    "    else:\n",
    "        x_start = dist - disthalfbin\n",
    "        x_stop = dist + disthalfbin\n",
    "\n",
    "    ts = tseries[i]['time_series']\n",
    "\n",
    "    v_all = ts.v.values\n",
    "    v = v_all[~np.isnan(v_all)]\n",
    "\n",
    "    start_dt64 = ts.acquisition_date_img1.values[~np.isnan(v_all)]\n",
    "    start_dec_year = vec_dt64_to_decimal_year(start_dt64)\n",
    "\n",
    "    stop_dt64 = ts.acquisition_date_img2.values[~np.isnan(v_all)]\n",
    "    stop_dec_year = vec_dt64_to_decimal_year(stop_dt64)\n",
    "\n",
    "    date_dt = ts.date_dt.values[~np.isnan(v_all)].astype('timedelta64[D]').astype(int)\n",
    "\n",
    "\n",
    "    column_pts = list( zip(date_dt,v,start_dec_year,stop_dec_year) )\n",
    "    column_pts.sort(reverse=True)\n",
    "\n",
    "    for date_dt,v,pt_start_dec_year,pt_stop_dec_year in column_pts:\n",
    "            cind=v\n",
    "            if cind>plot_speed_max:\n",
    "                cind=plot_speed_max\n",
    "            colorVal = scalarMap.to_rgba(cind)\n",
    "        \n",
    "            xvec=[x_start,x_stop,x_stop,x_start,x_start]\n",
    "            yvec=[pt_start_dec_year,pt_start_dec_year,pt_stop_dec_year,pt_stop_dec_year,pt_start_dec_year]\n",
    "            plotted_points.append((xvec,yvec,colorVal))\n",
    "            \n",
    "print(f'finished calculating {len(plotted_points)} polygons for plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45010c-c213-409e-84ae-eb9997f5802c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from pqdm.threads import pqdm\n",
    "\n",
    "fig2,ax2 = plt.subplots(1,figsize=(16.0,18.0), dpi=100)\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "if use_logscale == True:\n",
    "    ax2.set_title('speed evolution (color is speed (m/yr, log scale))')\n",
    "else:\n",
    "    ax2.set_title('speed evolution (color is speed (m/yr))')\n",
    "\n",
    "ax2.set_xlabel('position along profile (m)')\n",
    "ax2.set_ylabel('year')\n",
    "# label every year, with top of label at start of year\n",
    "ax2.set_yticks(np.arange(year_min,year_max,1.0))\n",
    "plt.setp( ax2.yaxis.get_majorticklabels(), va=\"top\" )\n",
    "\n",
    "ax2.set_autoscalex_on(False)\n",
    "ax2.set_xlim([dist_min, dist_max])\n",
    "ax2.set_autoscaley_on(False)\n",
    "ax2.set_ylim([year_min, year_max])\n",
    "ax2.invert_yaxis()\n",
    "# ax2.grid(axis='y',which='major',color='k',linestyle='-', alpha=0.75)\n",
    "ax2.grid(axis='y',which='both',color='k',linestyle='-', alpha=0.75)\n",
    "color_min=speed_min\n",
    "color_max=plot_speed_max\n",
    "\n",
    "\n",
    "def fill_points(point):\n",
    "    ax2.fill(point[0], point[1], color=point[2])\n",
    "\n",
    "results = pqdm(plotted_points, fill_points, n_jobs=8)\n",
    "\n",
    "# for point in pqdm(plotted_points, desc = 'plotting points'):\n",
    "#    ax2.fill(point[0],point[1],color=point[2])\n",
    "\n",
    "print('rendering figure...', flush=True)\n",
    "\n",
    "scalarMap._A=[]   # need to set this array even though not used in order to get colormap function to work\n",
    "cb2=plt.colorbar(scalarMap, ax=ax2, shrink = 0.8, extend = 'both')\n",
    "\n",
    "if use_logscale == True:\n",
    "    cb2_yticks = cb2.ax.get_yticks()\n",
    "    labels = []\n",
    "    for val in cb2_yticks:\n",
    "        if val >= 10 and val <= 1000:\n",
    "            labels.append(f\"{int(val):d}\")\n",
    "        else:\n",
    "            labels.append('')\n",
    "    cb2.ax.set_yticklabels(labels)\n",
    "\n",
    "\n",
    "y_formatter = mpl_ticker.ScalarFormatter(useOffset=False)\n",
    "ax2.yaxis.set_major_formatter(y_formatter)\n",
    "for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
    "             ax2.get_xticklabels() + ax2.get_yticklabels() + cb2.ax.get_yticklabels()):\n",
    "    item.set_fontsize(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be588c60-9760-4ee5-960a-5de6f21bbf15",
   "metadata": {
    "tags": []
   },
   "source": [
    "The profile is chosen with the first point (blue X in top figure) at the lower end of the ice (0 m at the left edge). In this plot the ice is flowing from the right to the left.\n",
    "\n",
    "One can see the seasonal cycle in speed (slowest in Fall) in the upper glacier, and the surge of the Malaspina 2020 and 2021, when the entire glacier along this centerline reached speeds > 2500 m/yr, or 6.8 m/day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37560d4-e4c2-42b0-bee9-7ebf81fa8db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
